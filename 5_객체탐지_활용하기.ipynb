{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66c4ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8500cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\Object_Detection_rep\\sample.jpg: 448x640 3 persons, 21.3ms\n",
      "Speed: 3.5ms preprocess, 21.3ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[150, 159, 202],\n",
       "         [152, 161, 204],\n",
       "         [151, 160, 203],\n",
       "         ...,\n",
       "         [138, 155, 198],\n",
       "         [139, 156, 199],\n",
       "         [139, 156, 199]],\n",
       " \n",
       "        [[150, 159, 202],\n",
       "         [152, 161, 204],\n",
       "         [151, 160, 203],\n",
       "         ...,\n",
       "         [138, 155, 198],\n",
       "         [138, 155, 198],\n",
       "         [138, 155, 198]],\n",
       " \n",
       "        [[150, 159, 202],\n",
       "         [152, 161, 204],\n",
       "         [151, 160, 203],\n",
       "         ...,\n",
       "         [137, 154, 197],\n",
       "         [138, 155, 198],\n",
       "         [138, 155, 198]]], dtype=uint8)\n",
       " orig_shape: (341, 512)\n",
       " path: 'c:\\\\githome\\\\Object_Detection_rep\\\\sample.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict'\n",
       " speed: {'preprocess': 3.5312999971210957, 'inference': 21.331800002371892, 'postprocess': 4.972800001269206}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "reslut = model('sample.jpg')\n",
    "reslut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c412b343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\Object_Detection_rep\\dog.jpg: 544x640 1 dog, 23.6ms\n",
      "Speed: 3.6ms preprocess, 23.6ms inference, 3.7ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Boxes object with attributes:\n",
       "\n",
       "cls: tensor([16.], device='cuda:0')\n",
       "conf: tensor([0.6653], device='cuda:0')\n",
       "data: tensor([[ 51.3454,  33.1425, 629.2720, 555.0193,   0.6653,  16.0000]], device='cuda:0')\n",
       "id: None\n",
       "is_track: False\n",
       "orig_shape: (577, 700)\n",
       "shape: torch.Size([1, 6])\n",
       "xywh: tensor([[340.3087, 294.0809, 577.9266, 521.8768]], device='cuda:0')\n",
       "xywhn: tensor([[0.4862, 0.5097, 0.8256, 0.9045]], device='cuda:0')\n",
       "xyxy: tensor([[ 51.3454,  33.1425, 629.2720, 555.0193]], device='cuda:0')\n",
       "xyxyn: tensor([[0.0734, 0.0574, 0.8990, 0.9619]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 바운딩박스, 라벨 출력\n",
    "result = model('dog.jpg')\n",
    "result[0].boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1277fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[101, 167, 162],\n",
       "        [ 96, 162, 157],\n",
       "        [ 93, 157, 151],\n",
       "        ...,\n",
       "        [ 79, 137, 132],\n",
       "        [ 71, 131, 125],\n",
       "        [ 69, 129, 123]],\n",
       "\n",
       "       [[ 98, 164, 159],\n",
       "        [ 95, 161, 156],\n",
       "        [ 94, 158, 152],\n",
       "        ...,\n",
       "        [ 82, 140, 135],\n",
       "        [ 79, 139, 133],\n",
       "        [ 79, 139, 133]],\n",
       "\n",
       "       [[ 94, 158, 153],\n",
       "        [ 95, 159, 154],\n",
       "        [ 96, 160, 154],\n",
       "        ...,\n",
       "        [ 85, 144, 136],\n",
       "        [ 87, 147, 139],\n",
       "        [ 88, 148, 140]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 24,  62,  74],\n",
       "        [ 28,  66,  78],\n",
       "        [ 54,  90, 100],\n",
       "        ...,\n",
       "        [  6,  70,  64],\n",
       "        [ 18,  90,  84],\n",
       "        [ 63, 140, 133]],\n",
       "\n",
       "       [[ 89, 125, 135],\n",
       "        [ 69, 105, 115],\n",
       "        [108, 144, 152],\n",
       "        ...,\n",
       "        [ 11,  78,  73],\n",
       "        [ 30,  97,  94],\n",
       "        [ 74, 142, 141]],\n",
       "\n",
       "       [[131, 164, 167],\n",
       "        [153, 186, 189],\n",
       "        [126, 162, 162],\n",
       "        ...,\n",
       "        [  0,  78,  73],\n",
       "        [ 23,  88,  89],\n",
       "        [ 56, 117, 119]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('dog.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dbc0f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for box in result[0].boxes:\n",
    "    class_id = box.cls[0]\n",
    "    class_name = model.names[class_id.item()]\n",
    "    \n",
    "    # 신뢰도 점수\n",
    "    conf = float(box.conf[0])\n",
    "    \n",
    "    #바운딩 박스\n",
    "    coords = box.xyxy[0].tolist()\n",
    "    x1, y1, x2, y2 = map(int, coords)\n",
    "    cv2.rectangle(img,(x1,y1), (x2,y2), (0,255,0), 2)\n",
    "    cv2.putText(img, f'{class_name} {conf:.4f}'\n",
    "                , (x1,y1-10), cv2.FONT_HERSHEY_PLAIN\n",
    "                , 1, (0,255,0),1)\n",
    "# end for\n",
    "\n",
    "cv2.imshow('yolov8 object detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('detect_result.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa360de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3d4efd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\Object_Detection_rep\\dog.jpg: 544x640 1 dog, 24.0ms\n",
      "Speed: 5.6ms preprocess, 24.0ms inference, 4.4ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "obb: None\n",
       "orig_img: array([[[101, 167, 162],\n",
       "        [ 96, 162, 157],\n",
       "        [ 93, 157, 151],\n",
       "        ...,\n",
       "        [ 79, 137, 132],\n",
       "        [ 71, 131, 125],\n",
       "        [ 69, 129, 123]],\n",
       "\n",
       "       [[ 98, 164, 159],\n",
       "        [ 95, 161, 156],\n",
       "        [ 94, 158, 152],\n",
       "        ...,\n",
       "        [ 82, 140, 135],\n",
       "        [ 79, 139, 133],\n",
       "        [ 79, 139, 133]],\n",
       "\n",
       "       [[ 94, 158, 153],\n",
       "        [ 95, 159, 154],\n",
       "        [ 96, 160, 154],\n",
       "        ...,\n",
       "        [ 85, 144, 136],\n",
       "        [ 87, 147, 139],\n",
       "        [ 88, 148, 140]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 24,  62,  74],\n",
       "        [ 28,  66,  78],\n",
       "        [ 54,  90, 100],\n",
       "        ...,\n",
       "        [  6,  70,  64],\n",
       "        [ 18,  90,  84],\n",
       "        [ 63, 140, 133]],\n",
       "\n",
       "       [[ 89, 125, 135],\n",
       "        [ 69, 105, 115],\n",
       "        [108, 144, 152],\n",
       "        ...,\n",
       "        [ 11,  78,  73],\n",
       "        [ 30,  97,  94],\n",
       "        [ 74, 142, 141]],\n",
       "\n",
       "       [[131, 164, 167],\n",
       "        [153, 186, 189],\n",
       "        [126, 162, 162],\n",
       "        ...,\n",
       "        [  0,  78,  73],\n",
       "        [ 23,  88,  89],\n",
       "        [ 56, 117, 119]]], dtype=uint8)\n",
       "orig_shape: (577, 700)\n",
       "path: 'c:\\\\githome\\\\Object_Detection_rep\\\\dog.jpg'\n",
       "probs: None\n",
       "save_dir: 'runs\\\\detect\\\\predict'\n",
       "speed: {'preprocess': 5.5850000062491745, 'inference': 23.98130000801757, 'postprocess': 4.433800000697374}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "reslut = model('dog.jpg')\n",
    "reslut[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d13dc71",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m img_new \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m overlay \u001b[38;5;241m=\u001b[39m img_new\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m# 마스크용\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m box \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# 마스크\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     polygon \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mxy[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m      8\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mfillPoly(overlay, [polygon],(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "img_new = cv2.imread('dog.jpg')\n",
    "overlay = img_new.copy() # 마스크용\n",
    "\n",
    "for box in zip(result[0].boxes, result[0].masks):\n",
    "    # 마스크\n",
    "    polygon = mask.xy[0].astype(np.int32)\n",
    "    cv2.fillPoly(overlay, [polygon],(0,255,0))\n",
    "    \n",
    "    \n",
    "    class_id = box.cls[0]\n",
    "    class_name = model.names[class_id.item()]\n",
    "    \n",
    "    # 신뢰도 점수\n",
    "    conf = float(box.conf[0])\n",
    "    \n",
    "    #바운딩 박스\n",
    "    coords = box.xyxy[0].tolist()\n",
    "    x1, y1, x2, y2 = map(int, coords)\n",
    "    cv2.rectangle(img_new,(x1,y1), (x2,y2), (0,255,0), 2)\n",
    "    cv2.putText(img_new, f'{class_name} {conf:.4f}'\n",
    "                , (x1,y1-10), cv2.FONT_HERSHEY_PLAIN\n",
    "                , 1, (0,255,0),1)\n",
    "# img + overlay 겹쳐서 출력\n",
    "alpha =0.5\n",
    "final_img = cv2.addWeighted(overlay,alpha, img_new, 1-alpha,0)\n",
    "\n",
    "#최종출력\n",
    "cv2.imshow('yolov8 object detection', final_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('detect_result.jpg',final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류(생략)\n",
    "# 자세"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7655bb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\Object_Detection_rep\\people.jpg: 640x448 1 person, 22.5ms\n",
      "Speed: 3.5ms preprocess, 22.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# YOLOv8 모델 로드\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "pose_result = model('people.jpg')\n",
    "img = cv2.imread('people.jpg')\n",
    "\n",
    "\n",
    "kp = pose_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d390d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\githome\\Object_Detection_rep\\people.jpg: 640x448 1 person, 24.1ms\n",
      "Speed: 3.7ms preprocess, 24.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# YOLOv8 Pose 모델 로드\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "\n",
    "# 이미지 추론\n",
    "pose_result = model('people.jpg')\n",
    "\n",
    "# 원본 이미지 불러오기\n",
    "img = cv2.imread('people.jpg')\n",
    "\n",
    "# 첫 번째 결과의 keypoints 추출\n",
    "keypoints = pose_result[0].keypoints.xy  # (사람 수, keypoint 수, 2)\n",
    "\n",
    "for person in keypoints:  # 사람 단위\n",
    "    for x, y in person:  # 각 keypoint\n",
    "        if x > 0 and y > 0:  # 유효한 좌표만\n",
    "            cv2.circle(img, (int(x), int(y)), 3, (255, 0, 0), -1)\n",
    "\n",
    "# 결과 시각화\n",
    "cv2.imshow('yolov8 pose', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('pose.jpg', img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfdd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2818a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda_yolo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
